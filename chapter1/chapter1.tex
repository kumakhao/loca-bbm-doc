\chapter{Einleitung}
\label{chap:einleitung}

In dieser Arbeit soll mit Hilfe einer Simulation untersucht werden, wie gut sich Kameras bei der Standortbestimmung in mobilen Roboter einsetzen lassen. Anlass dieser Arbeit war eine Anfrage der Künstlergruppe \ac{BBM}, die schon bei mehreren Performances\footnote{unter Anderem:
  
  2000 Themenpark "Wissen" der Expo 2000 Hannover
  
  2010 Joybots  in der BMW-Welt 
  
  2012 EPKOT Experimental Prototype Killers of Tomorrow , Hannover
  
  siehe auch \url{ http://www.bbm.cfnt3.de}} mobile Roboter eingesetzt hat. Diese fahren zum Teil in einer Choreografie über die Bühne. Um sie dabei eine vorgegebene Figur fahren zu lassen, muss der Steuerung bekannt sein, wo sich ein Roboter auf der Bühne aufhält. Eine solche Lokalisation war in der Vergangenheit für BBM sehr aufwendig. Aus diesem Grund interessierte sich die Künstlergruppe für eine Lokalisierungslösung, welche möglichst ohne weitere Spezialhardware und geringem Installationsaufwand vor Ort auskommt. Der Ansatz, der daraus entstand, war: die Kameras, die bereits an jedem der Roboter verbaut waren, zu nutzen, um markante Muster in der Bühneninstallation zu erkennen. Zusammen mit Messungen der Odometrie (sie beschreibt wie die Räder eines Roboters sich bei Bewegung drehen) soll die Position und Orientierung berechnet werden. Ein Partikelfilter ist als Zustandsschätzer zu verwenden. Zu der Bühneninstallation gehören große Lichtwände, zu sehen auf Abbildung \ref{fig:RobotAndGuests} und \ref{fig:RobotAndLightwall}. Auf diesen Lichtwänden wird ein hell/dunkel Bit-Muster angezeigt, welches es mit Hilfe geeigneter Bildverarbeitungsalgorithmen und mit den Kameras zu erkennen gilt.

  \begin{figure}[p]
    \centering
    \includegraphics[width=\textwidth]{chapter1/roboterAndLightwallOnEPKOT2.png}
    \caption[Roboter und Besucher auf der EPKOT]{Roboter und Besucher auf der EPKOT Quelle: http://www.bbm.cfnt3.de}
    \label{fig:RobotAndGuests}
    \bigskip 
    \includegraphics[width=\textwidth]{chapter1/roboterAndLightwallOnEPKOT.png}
    \caption[Roboter vor Lichtwand auf der EPKOT]{Roboter vor Lichtwand auf der EPKOT Quelle: http://www.bbm.cfnt3.de}
    \label{fig:RobotAndLightwall}
  \end{figure}
  
  \section{Ziel und Aufgabenstellung der Arbeit}
Im Rahmen dieser Arbeit soll eine Simulationsumgebung mit Hilfe geeigneter 3D-Visualisierungs-Bibliotheken erstellt werden. Diese soll in der Lage sein, eine 3D-Szene der Bühne zu simulieren und Kamerabilder sowie Odometrie-Daten einer Roboterfahrt zu erzeugen. Des weiteren soll ein Lokalisationsalgorithmus entwickelt werden, der auf Grundlage dieser Daten die Position und Orientierung des Roboters auf der Bühne schätzen kann. Anschließend soll die Qualität dieser geschätzten Position beurteilt und mögliche Fehlerquellen diskutiert werden.

  \section{Gliederung}
Im folgenden Kapitel soll eine kurze Übersicht über gängige Lokalisationsverfahren sowie deren Vor- und Nachteile gegeben werden. Außerdem sollen weitere Grundlagen zum besseren Verständnis der folgenden Kapitel vermittelt werden. Das Kapitel \textit{\nameref{chap:lokalisierungmittelsbildverarbeitung}} beschreibt, wie die Methoden aus den Grundlagen an das gestellte Problem angepasst wurden und wie das vorgestellte Verfahren funktioniert. Anschließend wird die Simulations- und Lokalisationssoftware vorgestellt, deren Implementation erklärt und begründet. Insbesondere soll auf die Realitätsnähe der Simulation eingegangen werden. In Kapitel \ref{chap:versuche} beginnt die Beschreibung verschiedener Versuche, die zum Beurteilen der Lokalisationsergebnisse durchgeführt wurden. Ergebnispräsentation und -diskussion erfolgen jeweils im Anschluss an die Beschreibungen. Abschließend wird ein Ausblick zur möglichen Anwendung dieses Verfahrens gegeben, sowie mögliche Fehlerquellen und Probleme dabei. Im letzten Kapitel wird ein Fazit zu den gewonnenen Erkenntnissen dieser Arbeit gezogen.
