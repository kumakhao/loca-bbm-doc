\chapter{Lokalisierung mittels Bildverarbeitung}
\label{chap:lokalisierungmittelsbildverarbeitung}

  \begin{wrapfigure}{o}{0.3\textwidth}
  	\center
    \includegraphics[width=0.2\textwidth]{chapter2.3/BitmusterVergleich.png}
    \caption[Bitmuster der Lichtwände]{Muster}
    \vspace{-70pt}
    \label{fig:bitmuster}
  \end{wrapfigure}
In diesem Kapitel soll das in dieser Arbeit entwickelte Verfahren beschrieben werden, mit dem die Lokalisierung erfolgt. Dabei wird erklärt wie das zu erkennende Bitmuster aufgebaut ist, wie der eingesetzte Partikelfilter ausgelegt wurde, und wie genau der Filter die Bilder beurteilt. Im letzten Abschnitt wird auf verschiedene Parameter eingegangen, die Einstellmöglichkeiten des Filters erlauben.
\section{Bitmuster}
\label{sec:bitmuster}
Die drei Bitmuster, in der Obersten Zeilen der Lichtwände, sind 64 Bit lang, da eine Lichtwand aus 8 Segmenten mit je 8 Bit aufgebaut ist. Jedes Segment ist 1~m lang. Damit ist ein Bit 125~x~125~mm groß. Als Muster wurde eine Zeichenfolge in Strichcode verwendet. Als Codierung wurde ein Verfahren gewählt, das Code 93\footnote{Quelle: http://www.suchymips.de/de/code-93.htm} genannt wird und von der Firma Intermec entwickelt wurde. Er codiert 48 verschiedene Zeichen in 9 Bit lagen Blöcken. Dabei sind mindestens 3 Bit immer \textbf{true}(1) und 3 immer \textbf{false}(0). Außerdem können höchstens 4 gleiche Bits auf einander folgen. Code 93 wurde gewählt, weil es schnell zu implementieren war, und sicher stellen konnte, dass es auch in beliebigen Ausschnitten der Muster genug Unterschiede zwischen den Lichtwänden gab. Auf Abbildung \ref{fig:bitmuster} sieht man die drei verwendeten Codestreifen. Rechts daneben sind die Zeichen für den codierten Abschnitt angegeben. Es sind 9 Bit lange Blöcke. Es gibt 7 solcher Blöcke die 63 Bits füllen, das letzte Bit ist bei zwei schwarz und einem weiß gewählt worden. Eine vollständige Tabelle der Codierung ist im Anhang auf Seite \pageref{fig:code93table} zu sehen.


\section{Partikelfilter}
\label{sec:PartikelFilter}
Für die Lokalisierung wird ein Partikelfilter verwendet. In diesem Abschnitt wird erläutert, wie dieser entworfen wurde, wie der Zustandsraum gewählt wurde und wie viele Partikel verwendet werden, wie das Dynamikmodell die Odometrie der Antriebe verwendet um die Pose des Roboters zu schätzen und wie im Messmodell die Bilder der Kamera verwendet werden. 
\subsection{Zustandsraum}
\label{subsec:zustandsraum}
Der Zustandsraum der Partikel setzt sich aus der Position und der Pose des Roboters zusammen. Da er sich ausschließlich auf einer ebenen Bühne befindet, führt dies zur Reduktion der Freiheitsgrade von sechs auf drei:
\begin{description}
\item[x und y ] sind die Koordinaten des Roboters auf der Bühne. Der Ursprung ist dabei in der Mitte der Bühne. Die x-Achse zeigt von der Bühnenseite ohne Lichtwand weg und auf die mittlere Lichtwand zu. Die z-Achse zeigt nach Oben und bildet zusammen mit der x- und y-Achse ein Rechtssystem. 
\item[Der Winkel $\mathbf{\psi}$] repräsentiert die Orientierung des Roboters relativ zur Bühne.Er ist zwischen Roboter x-Achse und Welt x-Achse (Bühne) bei Drehung um die z-Achse.
\end{description} 
Bei der Anzahl der Partikel gilt grundsätzlich, dass so viele wie möglich verwendet werden sollten wenn es auf die Genauigkeit des Filters ankommt. Beschränkt wird dies normalerweise von der zur Verfügung stehenden Rechenkapazität und der Zeit in der alle Partikel im Mess-Update verarbeitet werden sollen. Um Echtzeit fähig zu sein, spielt die Zeit eines Mess-Updates die entscheidende rolle. Unter diesem Aspekt wäre die Anzahl so groß wie nötig, aber so klein wie möglich zu wählen. Für die Simulation sollen 2500 Partikel eingesetzt werden. Dies sind verhältnismäßig wenig, Partikelanzahlen in der Literatur (\cite{Thrun2006}, \cite{Hertzberg2012}) sind meist im Bereich von mehreren Tausend Partikeln. In der Simulation scheinen aber 2500 Partikel zunächst ausreichend zu sein um die Lokalisation zu ermöglichen. Beim Einsatz auf einem Roboter wäre sie der Hardware angemessen zu wählen. Hinzu kommt, das der Algorithmus noch nicht auf Laufzeit optimiert werden konnte und so Simulationsläufe mit hohen Partikelzahlen unnötig lange gedauert hätten.

\subsection{Dynamikmodell}
\label{subsec:dynamikmodell}
Das Dynamikmodell für den Roboter basiert auf der Odometrie. Als Input bekommt das Dynamik-Update die Encoder-Messwerte des linken und rechten Rades. Es sind absolute Werte aus denen die Differenzen $ \Delta I_{r/l} $ zum letzten Update gebildet werden. Sie werden verwendet, um daraus eine Vorwärtsfahrt $ \Delta s $ und einen Drehwinkel $ \Delta \psi $ zu berechnen:
\begin{align}
\Delta s &= \frac{\Delta I_r + \Delta I_l}{2}\cdot \underbrace{\frac{2\pi r}{g \cdot \gamma}}_{E} \\
\Delta \psi &= \frac{\Delta I_r - \Delta I_l}{2}\cdot \frac{2\cdot E}{D}
\end{align}
mit Radabstand $ D $, Getriebeübersetztung $ g $, Radradius $r$ und Geberauflösung $ \gamma $

Jedes Partikel berechnet daraus seinen neuen Zustand:
\begin{align}
x_t &= x_{t-1} + cos(\psi_{t-1} + \frac{\Delta \psi}{2})\cdot \Delta s \\
y_t &= y_{t-1} + sin(\psi_{t-1} + \frac{\Delta \psi}{2})\cdot \Delta s \\
\psi_t &= \psi_{t-1} +\Delta \psi
\end{align}
Dabei wird rechnerisch erst eine Drehung um $ \frac{\Delta \psi}{2} $ vollzogen, gefolgt von der Geradeausfahrt um $ \Delta s $ mit einer abschließenden Drehung um $ \frac{\Delta \psi}{2} $.
Damit der Partikelfilter funktioniert, muss er die Messunsicherheiten der Eingangswerte berücksichtigen. Dazu wird vor der Zustandsberechnung, zu $ \Delta s $ und $ \Delta \psi $ ein Gaußsches Rauschen addiert. Es ist proportional zu deren Betrag:
\begin{align}
\Delta s_{err} &= \Delta s \cdot \sigma_{s} \cdot RandomGaussian() \\
\Delta \psi_{err} &= \Delta \psi \cdot \sigma_{\psi} \cdot RandomGaussian()
\end{align}

$ \sigma_{s} $ und $\sigma_{\psi}$ sind dabei ein Maß dafür wie breit die Streuung der Normalverteilung ist. Sie sind Parameter die auf den Anwendungsfall, nach Stärke des erwarteten Rauschens, eingestellt werden müssen. Dabei soll die Streuung der Partikel im Zustandsraum mindestens genau so groß sein, wie die Streuung um den wahren Wert, verursacht durch Messunsicherheit der Sensoren. Wir das $\sigma$ zu klein gewählt, so kann es  passieren, dass die Verteilung der Partikel den wahren Zustand nicht mehr enthält. Somit gibt es bei einer Messung kein Partikel mehr, dessen Zustand diese als wahrscheinlich erscheinen lässt. Damit folgen die Partikel im Zustandsraum einer falschen Schätzung, und die Messungen sind wertlos. Der Partikelfilter hätte die Position verloren.

Setzt man das $\sigma$ größer an, so divergieren die Partikel mit jedem Dynamik-Update stärker und der wahre Wert wird hoher Wahrscheinlichkeit von Partikeln abgedeckt, so dass bei einer Messung diese einen guten Score bekommen und durch ein Resampling sich die Partikel wieder um den wahren Wert konzentrieren. Allerdings ist bei zu großem $\sigma$ die Aussagekraft der Partikelverteilung sehr ungenau und es sind viele Partikel nötig, um die nötige Dichte im Zustandsraum zu gewährleisten. Dabei spielt es eine entscheidende Rolle, wie häufig Messungen erfolgen. Denn zwischen den Messungen muss sich der Filter auf das Dynamikmodell verlassen, und bei großem $\sigma$ ist die Schätzung nach wenigen Schritten bereits mit einer großen Unsicherheit verbunden.

\subsection{Messmodell}
\label{subsec:messmodell}
Als Messungen werden die Bilder einer Kamera auf dem Roboter verwendet. Das Messmodell dahinter beruht auf dem Wissen um die Position der erwähnten Mustern in der Umgebung. Dies kann als Karte der Umgebung verstanden werden, anhand derer sich der Roboter orientieren muss. Es gibt drei verschiedene Muster, auf jeder Lichtwand eines. Die Muster werden in der obersten Zeile der Lichtwand angezeigt, um möglichst selten verdeckt zu werden. Bei dem Messmodell gilt es nun zu prüfen, ob ein Bild zu einer bestimmten Pose passt oder nicht. Dafür könnte man in dem Bild nach den bekannten Mustern suchen, und sobald diese gefunden sind versuchen diese einer Pose zu zuordnen. Aber eine solche Mustersuche in einem Bild ist immer in verschiedene Schritte aufgeteilt, die auf einander aufbauen. Also z.B. Binarisierung über einen Schwellwert, Regionenbildung mit Charakterisierung und anschließende Auswertung ausgewählter Regionen. Oder Kantenerkennung, Hough-Transformation und finden von parallelen kurzen Linien. Ein Problem daran ist, dass wenn in einem ersten Schritt z.B. ein Schwellwert falsch gewählt wurde, oder nur sehr schwache Kanten vorhanden sind, alle folgenden Schritte scheitern, weil ihre Vorbedingungen nicht ausreichend erfüllt werden. Aus diesem Grund wurde ein anderer Ansatz verfolgt, bei dem man nicht das Bild und die Informationen darin als Ausgangspunkt nimmt, sondern die Pose der Partikel und die Position der Muster im Raum. Dazu wird aus den Koordinaten des Roboters auf der Bühne und dessen Ausrichtung die Pose der Kamera berechnet. Und anschließend die Position des Musters aus dem Raum in Pixelkoordinaten projiziert werden. Damit könnte man für jede beliebige Pose des Roboters sagen wo im Bild das Muster zu sehen sein müsste und diese Bereiche mit dem erwarteten Muster vergleichen. Je besser der Bereich zu dem Muster passt, umso höher wird der Score für die Partikelbewertung. Wie die gefundenen Pixel im Bild mit dem erwarteten Muster verglichen werden, wird in Abschnitt \ref{sec:musterbewertung} näher beschrieben. Um die Position des Musters im Bild aus der Roboter Position zu berechnen sind mehrere Koordinatentransformationen und eine Projektion nötig. Die Musterposition liegt als Punktmenge $M_W$ der Pixelmittelpunkte in Weltkoordinaten vor. Um sie mit der Kameragleichung in das Bild zu projizieren, müssen sie in die Kamerakoordinaten transformiert werden. Dazu sind folgende Schritte nötig:

\begin{description}
\item[Welt\ zu\ Roboter $(T_R^W)$] In diese Transformation fließt die Pose des Roboters ein, die in Weltkoordinate vorliegt. Diese Transformation besteht aus Translation in x- und y-Richtung sowie einer Drehung um die z-Achse mit dem Winkel $\psi$. Sie muss für jedes Partikel neu erzeugt werden. Da die Pose sich natürlich ständig ändert, und unter den Partikeln verschieden ist.
\begin{equation}
	T_R^W = \left( 
	\begin{array}{cccc}
		cos(\psi)	& -sin(\psi)			& 0 	& 0\\
		sin(\psi) 	& cos(\psi)		 	& 0 	& 0\\
		0 			& 0 					& 1	& 0\\
		0 			& 0 					& 0	& 1
	\end{array} \right)\cdot
	\left( 
	\begin{array}{cccc}
		1	& 0		& 0 	& x\\
		0 	& 1	 	& 0 	& y\\
		0 	& 0 		& 1	& 0\\
		0 	& 0		& 0	& 1
	\end{array} \right)
\end{equation}
\item[Roboter\ zu\ Kamera $(T_K^R)$] Diese Transformation entspricht der extrinsischen Kameramatrix, die die Pose der Kamera relativ zum Roboter ausdrückt. In der Simulation wurde sie in 500~mm Höhe am Roboter angebracht. Sie blickt in Fahrtrichtung und ist 30° nach Oben geneigt. Ist diese Transformation einmal bekannt, so kann sie immer wieder verwendet werden. In dieser Arbeit ist sie aus der Simulation bekannt. Aber bei einer realen Anwendung müsste zunächst eine Kamerakalibrierung durch geführt werden, um sie zu bestimmten. Um dieses Verfahren erst einmal untersuchen zu können, wird auf die Problematik der Kamerakalibrierung in dieser Arbeit nicht weiter eingegangen.
\end{description}
Durch Multiplikation der Transformationmatrizen
\begin{equation}
M_K=T_K^R \cdot T_R^W \cdot M_W
\end{equation}
erhält man die Koordinaten der Bitmuster im Kamerasystem $M_K$. Diese können nun mit einer perspektivischen Projektion
\begin{equation}
P\left(\begin{array}{c}
x\\
y\\
z\\
1
\end{array}\right)=
\left(\begin{array}{c}
\frac{x}{z} \\
\frac{y}{z} \\
1
\end{array}\right)
\end{equation}
und der intrinsichsen Kameramatrix
\begin{equation}
K_i = \left( \begin{array}{ccc}
f_x & 0 		& c_x \\
0 	& f_y 	& c_y \\
0 	& 0 		& 1\end{array} \right)
\end{equation}
in eine Punktmenge in Pixelkoordinaten $M_P$ projiziert werden
\begin{equation}
M_P = K_i\cdot M_K
\end{equation}

\subsection{Initialisierung}
\label{subsec:FilterInitialisierung}
Beim Start der Lokalisation muss den Partikeln eine Anfangsposition zugewiesen werden. Dies ist das in Abschnitt \ref{sec:lokalisation} beschriebene Teilproblem der Globalen Lokalisation. Eine übliche Vorgehensweise um einen sinnvollen Anfangszustand zu erhalten, ist die erste Messung zu verwenden und den gesamten Zustandsraum nach korrespondierenden Zuständen zu durchsuchen. Da ein durchsuchen des gesamten Raumes sehr lange dauern würde, wurde dieser eingegrenzt und damit eine Forderung an die Anfangs Pose des Roboters gestellt. Für die anfängliche Globale Lokalisierung muss der Roboter das Bit-Muster der mittleren Lichtwand sehen können. Es wird gefordert, das er in Richtung x-Achse ausgerichtet ist mit einer Toleranz von $\mp$ 20° der Blickrichtung. An die genaue Position auf der Bühne wird keine weitere Anforderung gestellt, solange das Bit-Muster im Bild ist, und der Blickwinkel in der Toleranz ist. In einer realen Anwendung würde der Roboter etwa mittig auf die Bühne gestellt und in Richtung der mittleren Lichtwand gedreht werden. Diese Globale Lokalisation würde ein paar Minuten brauchen und danach könnte der Roboter seinen Programmierten Weg abfahren. Da die Lokalisation nur einmal zu Beginn stattfinden muss, sollte dieses Verfahren kein Problem für die von BBM beschriebene Anwendung sein.
\subsection{Schätzung aus Partikeln berechnen}
\label{subsec:schaetzungBerechnen}
Der Algorithmus soll die Position des Roboters auf der Bühne, sowie dessen Orientierung angeben können. Weil der Partikel-Filter diese Information nur in der Partikelverteilung im Zustandsraum kennt, muss daraus eine geschätzte mittlere Position berechnet werden. Um einschätzen zu können, wie verlässlich diese Positionsangabe ist, wird außerdem noch die Varianz berechnet. Für die Position, als zweidimensionale Größe, wird sie als Ellipse um die Position ausgegeben und besteht aus großer Halbachse, kleiner Halbachse und Winkel zur x-Achse des Bühnenkoordinatensystems. Die Ellipse drückt den Vertrauensbereich aus, der 3$\sigma$ einer Normalverteilung entspricht. Für den Winkel wird neben dem Mittelwert die Standardabweichung berechnet. Damit steht die Mittlere Pose des Roboters über alle Partikel samt Standardabweichung zur Verfügung.
\section{Musterbewertung}
\label{sec:musterbewertung}
Bei der Musterbewertung geht es darum, zu einer bekannten Region im Bild eine Bewertung ab zu geben, wie gut sie zu einem gegebenen Muster passt. Bei der Bewertung wird zu jedem Bit des Musters geprüft, ob an dessen Position ein schwarzer oder ein weißer Wert vorliegt. Dabei soll ein Score berechnet werden der zwischen 0 und 1 liegt. Wobei 0 keinerlei und 1 volle Übereinstimmung signalisiert. Es ist gewollt, dass hier keine harte Entscheidung getroffen wird. Denn damit gehen Informationen verloren, die zur Lokalisierung beigetragen hätten. Wenn beispielsweise ein Teil des Musters verdeckt wurde, so wäre immer noch ein mittlerer Score möglich. Bei einer harten Entscheidung würde Partikel zu denen das Bild normalerweise passt genau so schlecht bewertet wie alle anderen. 

\subsection{Spezialfall: Projektion ergibt keine Bildpunkte}
\label{subsec:keineBildpunkte}
Für die Musterbewertung stehen die Bildpositionen jedes Bits der drei Bitmuster aus der Projektion zur Verfügung. Dabei entspricht sie stets dem Mittelpunkt der 125~x~125~mm großen Bits der Lichtwände. Der erste  Schritt ist eine einfache Überprüfung, ob die Pixelkoordinaten der Muster-Bits tatsächlich in dem Bild liegen. Denn die Projektion ist nicht auf einen Bildausschnitt beschränkt. Aus der Menge der Bildpunkte die ein Muster-Bit repräsentieren $M_P$ können so alle aussortiert werden, die nicht in dem betrachteten Bildausschnitt gelandet sind. Ein Spezialfall wäre nun, das kein Muster-Bit als Punkt im Bild gelandet ist. 
In diesem Fall wird ein fester Score gegeben, der nicht 0 sein darf. Genau 0 wäre für den Partikelfilter schlecht, da dieser das Gewicht des Partikels mit dem Score multipliziert um es zu bewerten. Es gibt hier zwei Fälle die zu unterscheiden sind:
\begin{description}
\item[Wahrer Zustand lässt kein Muster zu:] Der Roboter und damit die Kamera stehen so zu den Lichtwänden, dass sich kein Bit-Muster im Bild befindet. Damit gibt es, bei Partikeln die dieser Ausrichtung entsprechen, keine Punkte im Bild die sich auswerten lassen. Würde man einen Score von 0 geben, so würde der richtige Zustand, wegen der Multiplikation und anschließendem Resampling, gelöscht werden! Dies ist nicht erwünscht. Eine mögliche Lösung wäre in diesem Fall das Partikel mit einem mittlerem Score zu bewerten um den richtigen Zustand zu schützen. Ein zu hoher Score wäre jedoch im Folgenden Fall ungünstig.
\item[Falscher Zustand lässt kein Muster zu:] Ein Partikel, dessen Zustand stark von der wahren Pose abweicht, führt zu keinen Bildpunkten für das Bit-Muster. Im Bild befindet sich aber ein Bit-Muster. Deshalb müsste es andere Partikel geben, deren Zustände zum Bild passen und nicht automatisch einen festen Score bekommen. Würde nun, wie im ersten Fall vorgeschlagen, ein mittlerer Score gegeben, würde dieses Partikel überbewertet werden. Im Vergleich zu Partikeln dessen Zustand ein Bit-Muster an falscher Stelle vorhersagt, wäre dieser Fall erheblich besser bewertet. Auch wenn ein kleiner Wert gewählt wird, könnte eine ungünstige Vorhersage bei einem anderen Partikel einen schlechteren Score ergeben. Angestrebt wäre aber, dass dieser zweite Fall möglichst schlecht bewertet wird.
\end{description}
Deshalb wird ein Minimalscore von 0,01 festgelegt der in diesen Fällen gegeben wird. Zudem wird auch bei vorhandenem Bildpunkten für Bit-Muster bei dessen Auswertung mindestens dieser Minimalscore gegeben. Dadurch werden beim ersten Fall, bei dem kein richtiges Bit-Muster zum Auswerten im Bild ist, alle Partikel gleich bewertet. Da es kein Partikel gibt, das einen hohen Score bekommen kann. Es muss nur sichergestellt werden, dass die Auswertung beliebiger Bildpunkte als Bit-Muster den Minimalscore möglichst nicht übertrifft. Um dies zu prüfen, wurde zu einem Testbild (siehe Bild \ref{fig:randomRating}) für 1,8 Millionen Posen, die gleichmäßig über den Zustandsraum verteilt waren, der Score berechnet. Nur 136 davon lagen über dem Minimalscore von 0,01. Wie in Bild \ref{fig:randomRating} unten zu sehen, gibt es keine starke Häufung der Scores die über dem Minimum liegen, zudem ist kein Score über 0,25. Eine so geringe Anzahl von Überschreitungen des Minimalscores wird als akzeptabel angesehen.
\vspace{10pt}
\begin{figure}[h]
	\framebox[\textwidth]{
	\begin{minipage}{\textwidth} 
		\vspace{-20pt}
		\includegraphics[width=\textwidth]{chapter2.3/0000.jpg}	\newline
		\input{chapter2.3/randomRating.tex}
	\end{minipage}
	}
	\caption{1,8 Millionen Posen wurden mit dem Bild oben Bewertet. Nur 136 davon liegen über dem Minimalscore. Sie sind hier abgebildet.}
	\label{fig:randomRating}
\end{figure}

Werden alle mit dem selben Score bewertet, bleibt das Gewicht der Partikel ebenfalls gleich. Dies führt beim Resampling dazu, dass die Partikelverteilung erhalten bleibt. Beim zweiten Fall sollte es andere Partikel geben, deren Zustand zu dem Bild passt und die damit einen höheren Score bekommen. Wäre dies nicht der Fall, so wäre die Lokalisation fehlgeschlagen. Dadurch, dass der Minimalscore die geringste Bewertung ist die ein Partikel bekommen kann, gibt es das Problem einer Überbewertung nicht mehr.



\subsection{Mindestanzahl Auswertbarer Bildpunkte}
\label{subsec:mindesAnzahl}
Auch wenn es Punkte im Bild gibt, die mit dem Bit-Muster ausgewertet werden können, so erfolgt dies erst ab einer gewissen Anzahl. Für die Mindestanzahl auswertbarer Punkte wurde 18 gewählt. Damit soll verhindert werden, das zufällig wenige Punkte auf Bildbereichen liegen, die mehr oder weniger gut zum gesuchten Bit-Muster passen. Außerdem ist mit 18 Punkten sichergestellt, das keine Teile des Bit-Musters von einem Streifen auf einem anderen gefunden werden. Da die Codebausteine einzeln immer 9 Bits lang sind und im Gesamtmuster einzigartig. Wird diese Mindestanzahl nicht erfüllt, ergibt sich ebenfalls der Minimalscore.

\subsection{Bestimmung mittlerer Weiß- und Schwarzwerte}
\label{subsec:mittelWeissSchwarz}
Um einen Vergleich anstellen zu können, ob ein Bit im Bild schwarz oder weiß ist, sollen keine absoluten Weiß- und Schwarzwerte verwendet werden. Stattdessen wird über alle weißen Bits im Bild ein mittlerer Weißwert $\hat{h}_w$ errechnet:
\begin{equation}
\hat{h}_w = \frac{1}{n}\sum\limits_{i=1}^n h_w(i)
\end{equation}
Für den Schwarzwert $\hat{h}_s$ wird genauso verfahren. Aus diesen beiden Größen wird außerdem die Differenz  $\kappa$ gebildet:
\begin{equation}
\kappa=\hat{h}_w-\hat{h}_s
\end{equation}
An ihr lässt sich prüfen, ob sie negativ oder Null ist. Es würde darauf schließen lassen, dass ein falsches (oder kein) Muster vorliegt. Trifft dies zu, so wird der Minimalscore vergeben. 

\subsection{Bewertungskriterium}
\label{subsec:bewertungskriterium}
Für den Score $P$ der übrigen Bit-Musterpunkte wird ein quadratischer Abstand in der Helligkeit $\Delta h_i$ vom jeweiligen Referenzwert $\hat{h}$ verwendet:
\begin{equation}
\Delta h_i= (h_i-\hat{h}_{w/s})^2
\end{equation}
abhängig davon, ob im Muster ein schwarzes oder ein weißes Bit erwartet wird. Je größer dieser Abstand wird, umso schlechter passt dieses Bit aus dem Bild in das Bit-Muster. Würde man diesen Abstand direkt in den Score einfließen lassen, gäbe es bei sehr kontrastarmen Bildern ein Problem. Da der Vergleichswert für Schwarz und Weiß aus dem Bild berechnet wird, wären sie bei einfarbigen Flächen identisch. Denkbar wäre auch, dass eine solche einfarbige Fläche einen relativ hohen Score bekommt. Dies wäre bei ungünstigem Bildrauschen möglich, bei dem zufällig schwarze Bits dunkler und weiße Bits heller sind. Durch den geringen Kontrast sind die Abstände nur sehr klein, dies würde zu einem hohen Score führen.  Da dieser Abstand bei sinkendem Kontrast immer schwächer wird, fließt zusätzlich noch $\kappa$ mit in die Berechnung für den Score eines Bits $p_i$ ein:
\begin{equation}
p_i = \Delta h_i\cdot\frac{\kappa_{min}^2}{\kappa^2}
\end{equation}
mit $\kappa_{min}$ als Parameter lässt sich einstellen bis zu welcher Größe sich $\kappa$ negativ auf den Score auswirkt. Und ab wann es den Score positiv beeinflusst. Ein Wert von 20 für $\kappa_{min}$ reicht aus, um den Gesamtscore des Musters bei geringem Kontrast deutlich zu senken und Hilft bei gutem Kontrast den Score zu verbessern. Nach diesem Verfahren wird für jedes Bit ein solcher Score berechnet und der Mittelwert daraus gebildet:
\begin{equation}
\hat{p}=\frac{1}{n}\sum\limits_{i=1}^n (h_i-\hat{h}_{w/s})^2\cdot\frac{\kappa_{min}^2}{\kappa^2}
\end{equation}
Die Bildung des Mittelwertes ist nötig, damit der Score unabhängig von der Anzahl der sichtbaren Bits bleibt. Eine einfache Summe würde dazu führen, dass viele Bits einen schlechteren Score bekommen als wenige. Der letzte Schritte der Bewertung ist eine Exponentialfunktion mit negativem Exponenten:
\begin{equation}
P = e^{-\frac{\hat{p}}{2}}
\end{equation}
Sie führt bei sehr kleinem $\hat{p}$ zu einem Score nahe 1, während bei großem $\hat{p}$ der Score gegen 0 geht. Dieses Verhalten ist nötig um den Score mit dem Gewicht der Partikel multiplizieren zu können. Sie stellt sicher, dass der Score $P$ immer im Intervall $[0..1]$ bleibt
\section{Parameter einstellen}
\label{sec:parameter_loca}
An dieser Stelle soll beschrieben werden, mit welchen Größen das Verhalten von Filter und Bildbewertung beeinflusst werden können. Für den Filter lassen sich folgende Variablen verändern:
\begin{description}
\item [Anzahl der Partikel] ($N_p=2500$) Wie in Abschnitt \ref{subsec:zustandsraum} schon beschrieben werden 2500 Partikel eingesetzt. Je nach Anwendung muss ihre Anzahl angepasst werden. Sie ist dabei besonders von den Rechenkapazitäten abhängig die zur Verfügung stehen, sowie den zeitlichen Anforderungen.
\item[Raddurchmesser] ($R=80mm$) Der Filter nutzt diesen Parameter um aus Radumdrehungen eine zurückgelegte Strecke zu berechnen. Dies ist für die Berechnungen im Dynamik-Update relevant.
\item[Getriebeübersetzung] ($g=14,5$) Die Getriebeübersetzung wird vom Filter verwendet, um von Umdrehungen des Encoders in Radumdrehungen um zu rechnen. Dabei ist ein Verhältnis $g:1$ bzw. Encoder:Rad gemeint.
\item[Auflösung Drehimpulsgeber] ($\gamma=2000\frac{1}{U}$)
\item [Impulse pro Meter] ($I_m=57693.67$) Diese Größe kombiniert mehrere Maße und Parameter des Antriebs und des Encoders. Mit ihr lässt sich aus einer Anzahl von Impulsen des Encoders die gefahrene Strecke berechnen. Darin enthalten sind:
\begin{equation}
I_m=\frac{g\cdot \gamma}{2\pi R} =\frac{14,5\cdot 2000}{2\pi \cdot 0,08m} = 
57693,67\ \frac{1}{m}
\end{equation}
\item [Abstand zwischen den Rädern] ($D_{R}=700mm$) Dieser Parameter wird verwendet, um bei Drehungen den zurück gelegten Weg der Räder berechnen zu können. Im Filter wird aus Differenzen des linken und rechten Encoders damit ein Drehwinkel bestimmt.
\item [Unsicherheits Koeffizient Strecke] ($\sigma_s=0.2$) Diese Größe steuert wie groß das Rauschen ist welches auf die Bewegung eines Partikels wirkt. Dabei ist $\sigma_s$ eine Prozentgröße. Sie wird mit dem zu verrauschenden Wert und der Ziehung einer Gaußschen Normalverteilung multipliziert.
\item [Unsicherheits Koeffizient Drehung] ($\sigma_\psi=0.2$) Dieser Koeffizient ist ebenfalls eine prozentuale Größe wie $\sigma_s$. Er bezieht sich jedoch nur auf Drehungen. Er wird genau so verrechnet wie der Koeffizient für eine Strecke.
\end{description}
PicRating:
\begin{description}
\item[Mindestanzahl an sichtbaren Bits] ($B_{min}=18$) Bei der Bildauswertung werden Partikel automatisch mit dem Mindestscore bewertet, wenn weniger als $B_{min}$ Positionen für Bit-Muster berechnet wurden. Dies dient vor allem dem Schutz vor fehlerhaften hohen Scores durch zufälliges Übereinstimmen weniger Pixel im Bild.
\item[Kontrast Grenzwert] ($K_T=20$) Wenn der mittlere Kontrast über alle Pixel in den Bit-Musterpositionen kleiner wird als $K_T$, wird der Score abgewertet. Ist er größer, wird er verbessert.
\item[Größe Pixelgrid] ($U_{Pix}=1$) An den Positionen wo ein Bit-Muster vermutet wird, können unterschiedlich viele Pixel ausgewertet werden. Mit $U_{Pixel}=0$ würde nur ein Pixel an der Position betrachtet werden. Der wert gibt an wie viele Nachbar Pixel in jede Richtung mit in die Berechnungen einbezogen werden sollen. Ein Wert von 3 würde ein 7~x~7 Raster mit 49 Pixeln bedeuten.
\end{description}
