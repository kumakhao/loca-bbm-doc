\chapter{Lokalisierung mittels Bildverarbeitung}
\label{chap:lokalisierungmittelsbildverarbeitung}

  \begin{wrapfigure}{o}{0.3\textwidth}
  	\center
    \includegraphics[width=0.2\textwidth]{chapter2.3/BitmusterVergleich.png}
    \caption[Bitmuster der Lichtwände]{Muster}
    \vspace{-70pt}
    \label{fig:bitmuster}
  \end{wrapfigure}
In diesem Kapitel soll das in dieser Arbeit entwickelte Verfahren beschrieben werden, mit dem die Lokalisierung erfolgt. Dabei wird erklärt wie das zu erkennende Bitmuster aufgebaut ist, wie der eingesetzte Partikelfilter ausgelegt wurde, und wie genau der Filter die Bilder beurteilt. Im letzten Abschnitt wird auf verschiedene Parameter eingegangen, die Einstellmöglichkeiten des Filters erlauben.
\section{Bitmuster}
\label{bitmuster}
Die drei Bitmuster, in der Obersten Zeilen der Lichtwände, sind 64 Bit lang, da eine Lichtwand aus 8 Segmenten mit je 8 Bit aufgebaut ist. Jedes Segment ist 1~m lang. Damit ist ein Bit 125~x~125~mm groß. Als Muster wurde eine Zeichenfolge in Strichcode verwendet. Als Codierung wurde ein Verfahren gewählt, das Code 93\footnote{Quelle: http://www.suchymips.de/de/code-93.htm} genannt wird und von der Firma Intermec entwickelt wurde. Er codiert 48 verschiedene Zeichen in 9 Bit lagen Blöcken. Dabei sind mindestens 3 Bit immer \textbf{true}(1) und 3 immer \textbf{false}(0). Außerdem können höchstens 4 gleiche Bits auf einander folgen. Code 93 wurde gewählt, weil es schnell zu implementieren war, und sicher stellen konnte, dass es auch in beliebigen Ausschnitten der Muster genug Unterschiede zwischen den Lichtwänden gab. Auf Abbildung \ref{fig:bitmuster} sieht man die drei verwendeten Codestreifen. Rechts daneben sind die Zeichen für den codierten Abschnitt angegeben. Es sind 9 Bit lange Blöcke. Es gibt 7 solcher Blöcke die 63 Bits füllen, das letzte Bit ist bei zwei schwarz und einem weiß gewählt worden. Eine vollständige Tabelle der Codierung ist im Anhang auf Seite \pageref{fig:code93table} zu sehen.


\section{Partikelfilter}
\label{sec:PartikelFilter}
Für die Lokalisierung wird ein Partikelfilter verwendet. In diesem Abschnitt wird erläutert, wie dieser entworfen wurde, wie der Zustandsraum gewählt wurde und wie viele Partikel verwendet werden, wie das Dynamikmodell die Odometrie der Antriebe verwendet um die Pose des Roboters zu schätzen und wie im Messmodell die Bilder der Kamera verwendet werden. 
\subsection{Zustandsraum}
\label{subsec:zustandsraum}
Der Zustandsraum der Partikel setzt sich aus der Position und der Pose des Roboters zusammen. Da er sich ausschließlich auf einer ebenen Bühne befindet, führt dies zur Reduktion der Freiheitsgrade von sechs auf drei: X, Y und $\psi$. 

{\color{red} todo wieviel partikel, warum?}

\subsection{Dynamikmodell}
\label{subsec:dynamikmodell}
Das Dynamikmodell für den Roboter basiert auf der Odometrie. Als Input bekommt das Dynamik-Update die Inkremente des linken und rechten Rades. Es sind absolute Inkrementwerte aus denen die Differenzen $ \Delta I_{r/l} $ zum letzten Update gebildet werden. Sie werden verwendet, um daraus eine Vorwärtsfahrt $ \Delta s $ und einen Drehwinkel $ \Delta \psi $ zu berechnen:
\begin{align}
\Delta s &= \frac{\Delta I_r + \Delta I_l}{2}\cdot \underbrace{\frac{2\pi r}{g \cdot \gamma}}_{E} \\
\Delta \psi &= \frac{\Delta I_r - \Delta I_l}{2}\cdot \frac{2\cdot E}{D}
\end{align}
mit Radabstand $ D $, Getriebeübersetztung $ g $, Radradius $r$ und Geberauflösung $ \gamma $

Jedes Partikel berechnet daraus seinen neuen Zustand:
\begin{align}
x_t &= x_{t-1} + cos(\psi_{t-1} + \frac{\Delta \psi}{2})\cdot \Delta s \\
y_t &= y_{t-1} + sin(\psi_{t-1} + \frac{\Delta \psi}{2})\cdot \Delta s \\
\psi_t &= \psi_{t-1} +\Delta \psi
\end{align}
Dabei wird rechnerisch erst eine Drehung um $ \frac{\Delta \psi}{2} $ vollzogen, gefolgt von der Geradeausfahrt um $ \Delta s $ mit einer abschließenden Drehung um $ \frac{\Delta \psi}{2} $.
Damit der Partikelfilter funktioniert, muss er die Messunsicherheiten der Eingangswerte berücksichtigen. Dazu wird vor der Zustandsberechnung, zu $ \Delta s $ und $ \Delta \psi $ ein Gaußsches Rauschen addiert. Es ist proportional zu deren Betrag:
\begin{align}
\Delta s_{err} &= \Delta s \cdot \sigma_{s} \cdot RandomGaussian() \\
\Delta \psi_{err} &= \Delta \psi \cdot \sigma_{\psi} \cdot RandomGaussian()
\end{align}

$ \sigma_{s} $ und $\sigma_{\psi}$ sind dabei ein Maß dafür wie breit die Streuung der Normalverteilung ist. Sie sind Parameter die auf den Anwendungsfall, nach Stärke des erwarteten Rauschens, eingestellt werden müssen. Dabei soll die Streuung der Partikel im Zustandsraum mindestens genau so groß sein, wie die Streuung um den wahren Wert, verursacht durch Messunsicherheit der Sensoren. Wir das $\sigma$ zu klein gewählt, so kann es  passieren, dass die Verteilung der Partikel den wahren Zustand nicht mehr enthält. Somit gibt es bei einer Messung kein Partikel mehr, dessen Zustand diese als wahrscheinlich erscheinen lässt. Damit folgen die Partikel im Zustandsraum einer falschen Schätzung, und die Messungen sind wertlos. Der Partikelfilter hätte die Position verloren.

Setzt man das $\sigma$ größer an, so divergieren die Partikel mit jedem Dynamik-Update stärker und der wahre Wert wird hoher Wahrscheinlichkeit von Partikeln abgedeckt, so dass bei einer Messung diese einen guten Score bekommen und durch ein Resampling sich die Partikel wieder um den wahren Wert konzentrieren. Allerdings ist bei zu großem $\sigma$ die Aussagekraft der Partikelverteilung sehr ungenau und es sind viele Partikel nötig, um die nötige Dichte im Zustandsraum zu gewährleisten. Dabei spielt es eine entscheidende Rolle, wie häufig Messungen erfolgen. Denn zwischen den Messungen muss sich der Filter auf das Dynamikmodell verlassen, und bei großem $\sigma$ ist die Schätzung nach wenigen Schritten bereits mit einer großen Unsicherheit verbunden.

\subsection{Messmodell}
\label{subsec:messmodell}
Als Messungen werden die Bilder einer Kamera auf dem Roboter verwendet. Das Messmodell dahinter beruht auf dem Wissen um die Position der erwähnten Mustern in der Umgebung. Dies kann als Karte der Umgebung verstanden werden, anhand derer sich der Roboter orientieren muss. Es gibt drei verschiedene Muster, auf jeder Lichtwand eines. Die Muster werden in der obersten Zeile der Lichtwand angezeigt, um möglichst selten verdeckt zu werden. Bei dem Messmodell gilt es nun zu prüfen, ob ein Bild zu einer bestimmten Pose passt oder nicht. Dafür könnte man in dem Bild nach den bekannten Mustern suchen, und sobald diese gefunden sind versuchen diese einer Pose zu zuordnen. Aber eine solche Mustersuche in einem Bild ist immer in verschiedene Schritte aufgeteilt, die auf einander aufbauen. Also z.B. Binarisierung über einen Schwellwert, Regionenbildung mit Charakterisierung und anschließende Auswertung ausgewählter Regionen. Oder Kantenerkennung, Hough-Transformation und finden von parallelen kurzen Linien. Ein Problem daran ist, dass wenn in einem ersten Schritt z.B. ein Schwellwert falsch gewählt wurde, oder nur sehr schwache Kanten vorhanden sind, alle folgenden Schritte scheitern, weil ihre Vorbedingungen nicht ausreichend erfüllt werden. Aus diesem Grund wurde ein anderer Ansatz verfolgt, bei dem man nicht das Bild und die Informationen darin als Ausgangspunkt nimmt, sondern die Pose der Partikel und die Position der Muster im Raum. Dazu soll aus der Pose des Partikels die Pose der Kamera abgeleitet werden. Und anschließend die Position des Musters aus dem Raum in Pixelkoordinaten projiziert werden. Damit könnte man für jede beliebige Pose des Roboters sagen wo im Bild das Muster zu sehen sein müsste und diese Bereiche mit dem erwarteten Muster vergleichen. Je besser der Bereich zu dem Muster passt, umso höher wird der Score für die Partikelbewertung. Wie die gefundenen Pixel im Bild mit dem erwarteten Muster verglichen werden, wird in Abschnitt \ref{sec:musterbewertung} näher beschrieben. Um die Position des Musters im Bild aus der Roboter Position zu berechnen sind mehrere Koordinatentransformationen und eine Projektion nötig. Die Musterposition liegt als Punktmenge $M_W$ der Pixelmittelpunkte in Weltkoordinaten vor. Um sie mit der Kameragleichung in das Bild zu projizieren, müssen sie in die Kamerakoordinaten transformiert werden. Dazu sind folgende Schritte nötig:

\begin{description}
\item[Welt\ zu\ Roboter $(T_R^W)$] In diese Transformation fließt die Pose des Roboters ein, die in Weltkoordinate vorliegt. Diese Transformation besteht aus Translation in x- und y-Richtung sowie einer Drehung um die z-Achse mit dem Winkel $\psi$. Sie muss für jedes Partikel neu erzeugt werden. Da die Pose sich natürlich ständig ändert, und unter den Partikeln verschieden ist.
\item[Roboter\ zu\ Kamera $(T_K^R)$] Diese Transformation entspricht der extrinsischen Kameramatrix, die die Pose der Kamera relativ zum Roboter ausdrückt. In der Simulation wurde sie in 500~mm Höhe am Roboter angebracht. Sie blickt in Fahrtrichtung und ist 30° nach Oben geneigt. Ist diese Transformation einmal bekannt, so kann sie immer wieder verwendet werden. In dieser Arbeit ist sie aus der Simulation bekannt. Aber bei einer realen Anwendung müsste zunächst eine Kamerakalibrierung durch geführt werden, um sie zu bestimmten. Um dieses Verfahren erst einmal untersuchen zu können, wird auf die Problematik der Kamerakalibrierung in dieser Arbeit nicht weiter eingegangen.
\end{description}
Durch Multiplikation der Transformationmatrizen
\begin{equation}
M_K=T_K^R \cdot T_R^W \cdot M_W
\end{equation}
erhält man die Koordinaten der Bitmuster im Kamerasystem $M_K$. Diese können nun mit der intrinsichsen Kameramatrix
\begin{equation}
K_i = \left( \begin{array}{ccc}
f_x & 0 & c_x \\
0 & f_y & c_y \\
0 & 0 & 1 \end{array} \right)
\end{equation}
in eine Punktmenge in Pixelkoordinaten $M_P$ projiziert werden
\begin{equation}
M_P = K_i\cdot M_K
\end{equation}

\section{Musterbewertung}
\label{sec:musterbewertung}
Bei der Musterbewertung geht es darum, zu einer bekannten Region im Bild eine Bewertung ab zu geben, wie gut sie zu einem gegebenen Muster passt. Bei der Bewertung wird zu jedem Bit des Musters geprüft, ob an dessen Position ein schwarzer oder ein weißer Wert vorliegt. Dabei soll ein Score berechnet werden der zwischen 0 und 1 liegt. Wobei 0 keinerlei und 1 volle Übereinstimmung signalisiert. Es ist gewollt, dass hier keine harte Entscheidung getroffen wird. Denn damit gehen Informationen verloren, die zur Lokalisierung beigetragen hätten. Wenn beispielsweise ein Teil des Musters verdeckt wurde, so wäre immer noch ein mittlerer Score möglich. Bei einer harten Entscheidung würde Partikel zu denen das Bild normalerweise passt genau so schlecht bewertet wie alle anderen. 

\subsection{Spezialfall: Projektion ergibt keine Bildpunkte}
\label{subsec:keineBildpunkte}
Für die Musterbewertung stehen die Bildpositionen jedes Bits der drei Bitmuster aus der Projektion zur Verfügung. Dabei entspricht sie stets dem Mittelpunkt der 125~x~125~mm großen Bits der Lichtwände. Der erste  Schritt ist eine einfache Überprüfung, ob die Pixelkoordinaten der Muster-Bits tatsächlich in dem Bild liegen. Denn die Projektion ist nicht auf einen Bildausschnitt beschränkt. Aus der Menge der Bildpunkte die ein Muster-Bit repräsentieren $M_P$ können so alle aussortiert werden, die nicht in dem betrachteten Bildausschnitt gelandet sind. Ein Spezialfall wäre nun, das kein Muster-Bit als Punkt im Bild gelandet ist. 
In diesem Fall wird ein fester Score gegeben, der nicht 0 sein darf. Genau 0 wäre für den Partikelfilter schlecht, da dieser das Gewicht des Partikels mit dem Score multipliziert um es zu bewerten. Es gibt hier zwei Fälle die zu unterscheiden sind:
\begin{description}
\item[Wahrer Zustand lässt kein Muster zu:] Der Roboter und damit die Kamera stehen so zu den Lichtwänden, dass sich kein Bit-Muster im Bild befindet. Damit gibt es, bei Partikeln die dieser Ausrichtung entsprechen, keine Punkte im Bild die sich auswerten lassen. Würde man einen Score von 0 geben, so würde der richtige Zustand, wegen der Multiplikation und anschließendem Resampling, gelöscht werden! Dies ist nicht erwünscht. Eine mögliche Lösung wäre in diesem Fall das Partikel mit einem mittlerem Score zu bewerten um den richtigen Zustand zu schützen. Ein zu hoher Score wäre jedoch im Folgenden Fall ungünstig.
\item[Falscher Zustand lässt kein Muster zu:] Ein Partikel, dessen Zustand stark von der wahren Pose abweicht, führt zu keinen Bildpunkten für das Bit-Muster. Im Bild befindet sich aber ein Bit-Muster. Deshalb müsste es andere Partikel geben, deren Zustände zum Bild passen und nicht automatisch einen festen Score bekommen. Würde nun, wie im ersten Fall vorgeschlagen, ein mittlerer Score gegeben, würde dieses Partikel überbewertet werden. Im Vergleich zu Partikeln dessen Zustand ein Bit-Muster an falscher Stelle vorhersagt, wäre dieser Fall erheblich besser bewertet. Auch wenn ein kleiner Wert gewählt wird, könnte eine ungünstige Vorhersage bei einem anderen Partikel einen schlechteren Score ergeben. Angestrebt wäre aber, dass dieser zweite Fall möglichst schlecht bewertet wird.
\end{description}
Deshalb wird ein Minimalscore von 0,001 festgelegt der in diesen Fällen gegeben wird. Zudem wird auch bei vorhandenem Bildpunkten für Bit-Muster bei dessen Auswertung mindestens dieser Minimalscore gegeben. Dadurch werden beim ersten Fall, bei dem kein richtiges Bit-Muster zum Auswerten im Bild ist, alle Partikel gleich bewertet. Da es kein Partikel gibt, das einen hohen Score bekommen kann. Es muss nur sichergestellt werden, dass die Auswertung beliebiger Bildpunkte als Bit-Muster den Minimalscore nicht übertrifft. Werden alle mit dem selben Score bewertet, bleibt das Gewicht der Partikel ebenfalls gleich. Dies führt beim Resampling dazu, dass die Partikelverteilung erhalten bleibt. Beim zweiten Fall sollte es andere Partikel geben, deren Zustand zu dem Bild passt und die damit einen höheren Score bekommen. Wäre dies nicht der Fall, so wäre die Lokalisation fehlgeschlagen. Dadurch, dass der Minimalscore die geringste Bewertung ist die ein Partikel bekommen kann, gibt es das Problem einer Überbewertung nicht mehr.


\subsection{Mindestanzahl Auswertbarer Bildpunkte}
\label{subsec:mindesAnzahl}
Auch wenn es Punkte im Bild gibt, die mit dem Bit-Muster ausgewertet werden können, so erfolgt dies erst ab einer gewissen Anzahl. Für die Mindestanzahl auswertbarer Punkte wurde 18 gewählt. Damit soll verhindert werden, das zufällig wenige Punkte auf Bildbereichen liegen, die mehr oder weniger gut zum gesuchten Bit-Muster passen. Außerdem ist mit 18 Punkten sichergestellt, das keine Teile des Bit-Musters von einem Streifen auf einem anderen gefunden werden. Da die Codebausteine einzeln immer 9 Bits lang sind und im Gesamtmuster einzigartig. Wird diese Mindestanzahl nicht erfüllt, ergibt sich ebenfalls der Minimalscore.

\subsection{Bestimmung mittlerer Weiß- und Schwarzwerte}
\label{subsec:mittelWeissSchwarz}
Um einen Vergleich anstellen zu können, ob ein Bit im Bild schwarz oder weiß ist, sollen keine absoluten Weiß- und Schwarzwerte verwendet werden. Stattdessen wird über alle weißen Bits im Bild ein mittlerer Weißwert $\hat{h}_w$ errechnet:
\begin{equation}
\hat{h}_w = \frac{1}{n}\sum\limits_{i=1}^n h_w(i)
\end{equation}
Für den Schwarzwert $\hat{h}_s$ wird genauso verfahren. Aus diesen beiden Größen wird außerdem die Differenz  $\kappa$ gebildet:
\begin{equation}
\kappa=\hat{h}_w-\hat{h}_s
\end{equation}
An ihr lässt sich prüfen, ob sie negativ oder Null ist. Es würde darauf schließen lassen, dass ein falsches (oder kein) Muster vorliegt. Trifft dies zu, so wird der Minimalscore vergeben. 

\subsection{Bewertungskriterium}
\label{subsec:bewertungskriterium}
Für den Score $P$ der übrigen Bit-Musterpunkte wird ein quadratischer Abstand in der Helligkeit $\Delta h_i$ vom jeweiligen Referenzwert $\hat{h}$ verwendet:
\begin{equation}
\Delta h_i= (h_i-\hat{h}_{w/s})^2
\end{equation}
abhängig davon, ob im Muster ein schwarzes oder ein weißes Bit erwartet wird. Je größer dieser Abstand wird, umso schlechter passt dieses Bit aus dem Bild in das Bit-Muster. Würde man diesen Abstand direkt in den Score einfließen lassen, gäbe es bei sehr kontrastarmen Bildern ein Problem. Da der Vergleichswert für Schwarz und Weiß aus dem Bild berechnet wird, wären sie bei einfarbigen Flächen identisch. Denkbar wäre auch, dass eine solche einfarbige Fläche einen relativ hohen Score bekommt. Dies wäre bei ungünstigem Bildrauschen möglich, bei dem zufällig schwarze Bits dunkler und weiße Bits heller sind. Durch den geringen Kontrast sind die Abstände nur sehr klein, dies würde zu einem hohen Score führen.  Da dieser Abstand bei sinkendem Kontrast immer schwächer wird, fließt zusätzlich noch $\kappa$ mit in die Berechnung für den Score eines Bits $p_i$ ein:
\begin{equation}
p_i = \Delta h_i\cdot\frac{\kappa_{min}^2}{\kappa^2}
\end{equation}
mit $\kappa_{min}$ als Parameter lässt sich einstellen bis zu welcher Größe sich $\kappa$ negativ auf den Score auswirkt. Und ab wann es den Score positiv beeinflusst. Ein Wert von 20 für $\kappa_{min}$ reicht aus, um den Gesamtscore des Musters bei geringem Kontrast deutlich zu senken und Hilft bei gutem Kontrast den Score zu verbessern. Nach diesem Verfahren wird für jedes Bit ein solcher Score berechnet und der Mittelwert daraus gebildet:
\begin{equation}
\hat{p}=\frac{1}{n}\sum\limits_{i=1}^n (h_i-\hat{h}_{w/s})^2\cdot\frac{\kappa_{min}^2}{\kappa^2}
\end{equation}
Die Bildung des Mittelwertes ist nötig, damit der Score unabhängig von der Anzahl der Bits im Bild bleibt. Eine einfache Summe würde dazu führen, dass viele Bits einen schlechteren Score bekommen. Der letzte Schritte der Bewertung ist eine Exponentialfunktion mit negativem Exponenten:
\begin{equation}
P = e^{-\frac{\hat{p}}{2}}
\end{equation}
\section{Parameter einstellen}
\label{sec:parameter_loca}
{\color{red}
Wieviele Partikel, und warum?

Wie sieht der Partikelraum aus? 

Wie ist das Messmodell aufgebaut?

Besonderheiten im Messmodell: erst an 10 Punken wird ausgewertet, geringer Kontrast führt zu Abwertung.

Wie wird initialisiert? 

Wie ist das Dynamikmodell aufgebaut?

Wie ist das Muster aufgebaut?

Wie wird die "geschätzte" Position berechnet?
}
