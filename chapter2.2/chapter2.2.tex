\chapter{Software}
\label{chap:software}
Die Software die im Rahmen dieser Arbeit entwickelt wurde, ist in C++ geschrieben. Als Entwicklungsumgebung wurde Eclipse mit den \ac{CDT} auf einem Linux\footnote{Ubuntu 12.04 LTS}  Betriebssystem verwendet.
\section{Simulation}
\label{sec:simulation}
Grundlage der Simulation ist das 3D Grafiktoolkit \ac{OCG}\footnote{\url{http://www.openscenegraph.org/}}. Damit lässt sich eine 3D Szene in Form eines Graphen aufbauen und mit einem Viewer darstellen. Um den Ablauf kontrollieren zu können, lässt sich die Render-Schleife manuell aufrufen um jeden Frame einzeln berechnen zu lassen. Dies wurde als Simulationsschritt gewählt in dem alle nötigen Berechnungen durchgeführt werden können. Da die Geschwindigkeit mit der die Simulation im manuellen Modus abläuft nicht begrenzt wird, wurde eine Mindestbearbeitungszeit integriert. Denn die Geschwindigkeiten von Objekten in der Simulation, wie dem Roboter, werden durch eine zurückgelegte Strecke pro Simulationsschritt festgelegt. Bei sehr schneller Hardware ergab dies eine zu hohe Bewegungsrate um den Roboter noch manuell steuern zu können. Für automatisierte Simulationsläufe mit festgelegten Fahrprofilen könnte man diese Begrenzung wieder lösen um Zeit zu sparen.

\subsection{Die Szene}
\label{subsec:dieSzene}
Die Szene in der Simulation ist aus mehreren Komponenten aufgebaut, die im Folgenden näher beschrieben werden. Dabei wird ein Vergleich zu den echten Elementen auf der Bühne gezogen, um zu erläutern wie deren Attribute in der Simulation abgebildet werden können. In Abbildung \ref{fig:bildderszene} kann man alle Elemente der Szene erkennen. 
\begin{description} 
\item[Die Grundfläche (1)] der Bühne misst 12 x 12 m. Sie wird als einfach weiße Fläche in der Szene dargestellt. Da die Bildverarbeitung nur auf den Oberen Teil des Bildes beschränkt ist, spielen Farbe und Helligkeit keine Rolle bei der Erkennung des Musters im Bild.
\end{description}
 
\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{chapter2.2/bildderszene.png}
    \caption[Bild Simulierte Szene]{Bild Simulierte Szene}
    \label{fig:bildderszene}
\end{figure}

\begin{description}
\item[Die Lichtwände (2,3)] sind zu drei Seiten der Grundfläche aufgestellt. Sie messen 3m in der Höhe und 8m  in der Länge. Wie bereits in @@@@@@@@ beschrieben soll das Muster in der obersten Zeile der Lichtwände dargestellt werden. Hierzu können verschiedene Texturen geladen werden die das Bitmuster enthalten. In der Realität sind die Lichtwände auf der Bühne sind aus 1 x 1 Meter großen Segmenten zusammen gesetzt, dies wird in der Simulation nicht abgebildet. Es wäre jedoch denkbar, dies in den Aufbau der Texturen einfließen zu lassen. Also leichte Abstands Änderungen der Bits in der Textur.
Auf jedem Segment sind 8 x 8 Bits unter gebracht. Das macht eine Kantenlänge von 125 mm bei jedem dieser Pixel und 64 Pixel über die ganze Länge einer Wand. Ein solches Segment besteht aus einer Milchigen Plexiglasplatte, die auf eine Struktur geschraubt wurde die für jedes Pixel ein Leuchtmittel vorsieht. Dessen Helligkeit lässt sich einstellen, wäre aber für das Bitmuster auf die Zustände: dunkel(ausgeschaltet) oder hell(ein, mit größter Helligkeit) einzustellen. Die Plexiglasplatte wird also pro Pixel von Hinten durchleuchtet. Dies führt dazu, das die Helligkeitsverteilung in einem beleuchteten Pixle inhomogen ist. In der Mitte ist die größte Helligkeit, während sie radial nach Außen etwas abnimmt. Die Ecken der Pixle sind die dunkelsten Stellen. Auf Abbildung \ref{fig:RobotAndLightwall} auf Seite \pageref{fig:RobotAndLightwall} ist dieser Effekt gut zu sehen. Er wird besonders stark, wenn die Leuchtmittel mit niedriger Helligkeit betrieben werden. Bei hoher Helligkeit ist der Effekt noch wahrnehmbar, aber nicht mehr so ausgeprägt. Und noch etwas fällt auf wenn man dieses Bild betrachtet, die Lichtfarbe und Helligkeit variiert leicht von Pixel zu Pixel. All diese Effekte können in der Simulation nur durch verändern der Texturen abgebildet werden.

\item[Der Roboter (4)] @@@@@@@@@@@@@@@ Platzhalter @@@@@@@@@@@@ Er lässt sich mit den Tasten W, A, S, D (vorwärts, links, rückwärts, rechts) grob verfahren oder mit einem Pad mit Analogsticks auch präziser steuern. Die Steuerbefehle für den Roboter werden in Geschwindigkeit (gerade aus) und Drehrate interpretiert. Diese führen dann, in jedem Simulationsschritt zu einer Positionsänderung in Richtung der Orientierung und einer anschließenden Änderung der Orientierung um die Drehrate. <------( Implementierung möglicherweise noch ändern??? ) . 

\item[Passanten oder Besucher (5)] @@@@@@@@@@@ Platzhalter @@@@@@@@@@@

\item[Partikel (6)] werden zur Veranschaulichung und zu debugging Zwecken visualisiert. Sie werden durch rote kleine spitze Dreiecke dargestellt. Der spitze Winkel zeigt dabei die Orientierung an. Sie befinden sich nur auf dem Boden und beeinträchtigen die Bildverarbeitung deshalb nicht.
\end{description}

\subsection{Messen in der Simulation}
\label{subsec:MessenInDerSimulation}
Die Simulation soll, neben der Visualisierung, Messungen liefern um den Lokalisationsalgorythmus testen zu können. Anders als bei Messungen an realen Experimenten hat man in der Simulation den Vorteil, alle das Messergebnis beeinflussenden Faktoren unter Kontrolle zu haben. Möchte man also, dass Messungen eine systematische Abweichung aufweisen, muss diese in der Simulation definiert werden. Genau so verhält es sich mit statistischen Abweichungen. Es lassen sich also schnell die Messunsicherheiten der Simulierten Vorgänge anpassen. Beim Debugging und Funktionstest des Lokalisationsalgorythmus wurde die Unsicherheit zum Beispiel zeitweise entfernt.

\subsubsection*{Messwerte der Inkrementalgeber}
Wie beim Robotermodell schon beschrieben, wird in der Simulation dessen X/Y-Koordinate sowie der Winkel zur X-Achse als Repräsentation der Pose verwendet. Aus den Positions- ($ \Delta s $) und Orientierungsänderungen ($ \Delta \psi $), in jedem Simulationsschritt, werden Drehwinkeländerungen ($ \Delta \alpha $) der Beiden Räder berechnet:

\[\Delta \alpha_{l/r} = \underbrace{\Delta s \pm \Delta \psi \cdot \frac{L_{achse}}{2}}_{zurückgelegte\ Strecke\ pro\ Rad} \cdot \frac{\gamma}{U_{rad}\cdot g} \]

mit Länge der Achse: $ L_{achse} $, Radumfang: $ U_{rad} $, Getriebeübersetzung: $ g $ und Inkrementalgeber Auflösung: $ \gamma $ (pro Umdrehung)

Über alle Schritte akkumuliert, ist der Drehwinkel der Räder ($ \alpha_{l/r} $) der wahre Zustand der Odometrie in der Simulation. Aus diesen Winkelstellungen\footnote{Die Winkelstellung der Räder wird nur numerisch simuliert und ist am Modell nicht sichtbar.}  der Räder wird ein Wert für die Inkrementalgeber abgeleitet und auf ganze Inkremente gerundet.

\subsubsection*{Bilder eine Kamera}
noch mehr test text zum testen.

\section{Lokalisation}
\label{sec:lokalisation}
Die Lokalisation ist als eine Klasse implementiert 