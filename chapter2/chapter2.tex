\chapter{Grundlagen}
\label{chap:grundlagen}

\section{Lokalisation}
\label{sec:lokalisation}
Die Lokalisation ist eines der Grundprobleme das beim Einsatz von mobilen Robotern auftritt.

In \cite[Seite 193]{Thrun2006} wird die Lokalisation in drei Teilprobleme zerlegt:
\begin{description}
\item[Position Tracking] bezeichnet den Vorgang, bei dem mit bekannter Ausgangsposition diese mit Hilfe von Sensordaten bei Bewegungen verfolgt werden kann. Dabei spielt das Dynamikmodell des Roboters sowie darin modellierte Unsicherheiten eine wichtige Rolle. Denn bewegt sich der Roboter von einer bekannten Position aus, wird mit dem Dynamikmodell seine neue Position geschätzt. Bekannte Unsicherheiten des Modells erzeugen eine Wahrscheinlichkeitsverteilung um diese neue Position, in der sich die wahre Position befinden sollte. Ohne Messungen von weiteren Sensoren die Rückschlüsse auf die Umgebung erlauben, würde die Positionsschätzung mit der Zeit immer ungenauer. Mit Hilfe eines Messmodells lässt sich beurteilen, ob eine Messung an einer Bestimmten Position wahrscheinlich erscheint, oder nicht. Dadurch lässt sich die Wahrscheinlichkeitsverteilung der Position nach einer Bewegung durch eine Messung wieder eingrenzen. Auf den Bereich, in dem der Messwert des Sensors am Wahrscheinlichsten ist.
\item[Global Localization] ist das finden der Anfangsposition des Roboters unter allen Möglichen Posen die im Szenario vorkommen können. Im Vergleich zum \textit{Position Tracking}, bei dem es genügte die Unsicherheit um die geschätzte neue Pose zu berücksichtigen, umfasst hier der Raum möglicher Posen ein erheblich größeres Volumen. Ein Ansatz wäre alle möglichen Posen mit der selben Wahrscheinlichkeit anzunehmen, und mit den ersten Messungen und dem Messmodell diese einzugrenzen. Auf Bereiche in denen diese Messungen mit hoher Wahrscheinlichkeit auftritt. 
\item[Kidnapped Robot Problem] ist eine verschärfte Variante des \textit{Global Localization} Problems. Dabei geht man davon aus, das sich der Roboter spontan an einem anderen Ort aufhält als vom Roboter angenommen. Nun müsste die Lokalisation des Roboters wieder im gesamten möglichen Raum erfolgen. Nur das der Roboter diesen Zustand nicht feststellen kann. 
\end{description}

\subsection{Übersicht gängiger Verfahren}
\label{subsec:uebersichtVerfahren}
Die meisten Lösungsansätze verwenden im Grunde eine Variante des Bayes-Filters wie z.B. in \cite[Seite 26]{Thrun2006} beschrieben. Abhängig vom Einsatzumfeld und der verwendeten Hardware gibt es aber noch Andere Verfahren.

In \cite{seco2009survey} zum Beispiel werden, neben dem Bayes-Filter, drei weitere genannt: \textit{Geometry-Based Methods}, \textit{Minimization of the cost function} und \textit{Fingerprint Methods} die sich in Gebäuden unter Nutzung von Elektromagnetischen Signale verwenden lassen. Je nach Sensorausstattung werden verschiedene Karten der Umgebung verwendet. Auf die sich der Roboter durch Auswertung von Sensormessungen lokalisieren muss. Dabei gibt es Karten die vorher angefertigt wurden, und dem Roboter bereits zur Verfügung stehen. Und es gibt Karten die der Roboter selbstständig während der Lokalisation erstellen muss. Letzteres wird als \ac{SLAM} Problem bezeichnet zu dem es bereits viele Veröffentlichungen gibt (u.a.) \cite[Seite 309]{Thrun2006}, \cite{Thrun:2002:PFR:2073876.2073937}, \cite[Seite 229]{Hertzberg2012}

Der in Kapitel \ref{chap:einleitung} genannte Partikel Filter ist eine Variante des Bayes-Filters. Weitere Verfahren findet man unter folgenden Stichwortern: \textsc{Kalman Filter} (EKF, UKF), \textsc{Partikel Filter} oder \textsc{Sequenzielle Monte-Carlo-Methode}, \textsc{Grid-Based-Filter} oder \textsc{Histogram Filter (continous Space)}, \textsc{discrete Bayes Filter (discrete Space)}

\cite{Thrun:2002:PFR:2073876.2073937} 

\subsection{Der Partikel Filter}
\label{subsec:partikelfilter}

\section{Bildverarbeitung}
\label{sec:bildverarbeitung}
Da die von einer Kamera aufgenommenen Bilder in dieser Arbeit eine zentrale Rolle spielen, ist es wichtig zu verstehen, wie diese zustande kommen. Daher soll an dieser Stelle kurz darauf eingegangen werden, wie sich eine Kamera formal beschreiben lässt.
\subsection{Kamera Modell}
Die Lochkamera ist ein sehr einfaches Modell das häufig zur Veranschaulichung verwendet wird. Es soll hier nicht im Detail beschrieben werden, dafür wären ... oder ... zu empfehlen. Doch für das hier vorgestellte Verfahren ist es wichtig das Konzept dahinter zu verstehen:

Die Kamera projiziert im Wesentlichen Punkte aus dem Raum(3D) auf die Bildebene(2D). Um nun bei gegebenen Koordinaten eines 3D-Punktes in Weltkoordinaten den passenden Punkt auf der Bildebene berechnen zu können, ist die Kenntniss verschiedener Parameter erforderlich. Dabei trennt man in extrinsische und intrinsische Parametern. Unter den extrinsichen Kamera Parametern versteht man die Pose der Kamera in Weltkoordinaten. Also wo sich die Kamera befindet, und wie sie ausgerichtet ist. Dies wird in einer Transformationsmatrix ausgedrückt, mit der sich Koordinaten zwischen dem Kamerakoordinatensystem und dem Weltkoordinatensystem  transformieren lassen.

Die intrinsischen Parameter sind nötig, um 3D-Punkte (in Kamerakoordinaten) auf die Bildebene zu projizieren. 

\subsection{Projektion aus dem Raum auf die Bildebene}
\label{subsec:projektion}

