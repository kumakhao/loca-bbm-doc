\chapter{Grundlagen}
\label{chap:grundlagen}

\section{Der Roboter}
\label{derroboter}
An dieser Stelle soll kurz beschrieben werden, wie die Roboter aufgebaut sind die als Grundlage für die Simulation dienen. Auf den Abbildungen~\ref{fig:RobotAndGuests}, \ref{fig:RobotAndLightwall} und \ref{fig:RobotCloseUp} sind sie zu sehen. Sie besitzen zwei angetriebene Räder und mindestens ein weiteres Stützrad, das frei drehbar ist. Die Räder können unabhängig von einander angetrieben werden. Dazu sind pro Rad ein Servomotor mit Motorsteuerung und ein Getriebe mit Übersetzung verbaut.
  \begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{chapter2/RobotNahaufnahme.png}
    \caption[Nahaufnahme eines der Roboter]{Einer der Roboter in Nahaufnahme}
    \label{fig:RobotCloseUp}
  \end{figure}
Zudem ist an jedem Rad ein Inkrementalgeber angebracht, der die Umdrehungen der Motorwelle misst. Es gibt verschiedene Baugrößen, der Antrieb ist aber bei allen gleich. Die Räder haben einen Durchmesser von  160~mm, das Getriebe hat ein Übersetzungsverhältnis von 1:14,5 und die Inkrementalgeber haben eine Auflösung von 2000 Ticks pro Umdrehung. Lediglich der Radstand unterscheidet sich bei den Baugrößen. Für die Simulation wird mit 700~mm gearbeitet.

\section{Bühneninstallation}
\label{buehneninstallation}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{chapter2/BuehneVonOben.png}
	\caption[Bühnenmodell]{Ein Modell einer möglichen Bühne}
	\label{fig:buehnenmodell}
\end{figure}
Zum Zeitpunkt dieser Arbeit gab es keine stehende Bühne die man hätte zeigen können. Deshalb wurde nach Vorgabe eine mögliche Installationsanordnung modelliert. In Abbildung \ref{fig:buehnenmodell} sieht man von schräg oben eine 12~x~12~m Grundfläche. An drei Seiten stehen so genannte Lichtwände die 3~m hoch und 8~m breit sind. 

\section{Lokalisation}
\label{sec:lokalisation}
Die Lokalisation ist eines der Grundprobleme das beim Einsatz von mobilen Robotern auftritt.
In \cite[Seite 193]{Thrun2006} wird es in drei Teilprobleme zerlegt:
\begin{description}
\item[Position Tracking] bezeichnet den Vorgang, bei dem mit bekannter Ausgangsposition diese mit Hilfe von Sensordaten bei Bewegungen verfolgt werden kann. Dabei spielt das Dynamikmodell des Roboters sowie darin modellierte Unsicherheiten eine wichtige Rolle. Denn bewegt sich der Roboter von einer bekannten Position aus, wird mit dem Dynamikmodell auf Grund der Odometrie seine neue Position geschätzt. Die Unsicherheiten des Modells erzeugen dabei eine Wahrscheinlichkeitsverteilung um diese neue Position, in der sich die wahre Position befinden sollte. Ohne Messungen von weiteren Sensoren die Rückschlüsse auf die Umgebung erlauben, würde die Positionsschätzung mit der Zeit immer ungenauer. Mit Hilfe eines Messmodells lässt sich beurteilen, ob eine Messung an einer Bestimmten Position wahrscheinlich erscheint, oder nicht. Dadurch lässt sich die Wahrscheinlichkeitsverteilung der Position nach einer Bewegung durch eine Messung wieder eingrenzen. Auf den Bereich, in dem der Messwert des Sensors am wahrscheinlichsten ist.
\item[Global Localization] ist das Finden der Anfangsposition des Roboters unter allen möglichen Posen die im Szenario vorkommen können. Im Vergleich zum \textit{Position Tracking}, bei dem es genügte die Unsicherheit um die geschätzte neue Pose zu berücksichtigen, umfasst hier der Raum möglicher Posen ein erheblich größeres Volumen. Ein Ansatz wäre alle möglichen Posen mit der selben Wahrscheinlichkeit anzunehmen, und mit den ersten Messungen und dem Messmodell diese auf Bereiche einzugrenzen in denen diese Messungen mit hoher Wahrscheinlichkeit auftritt. Das ist natürlich viel aufwendiger als Position Tracking und kann bei einem großen Zustandsraum sehr lange Dauern.
\item[Kidnapped Robot Problem] ist eine verschärfte Variante des \textit{Global Localization} Problems. Dabei geht man davon aus, das sich der Roboter spontan an einem anderen Ort aufhält als vom Roboter angenommen. Nun müsste die Lokalisation des Roboters wieder im gesamten möglichen Raum erfolgen. Nur das der Roboter diesen Zustand nicht feststellen kann. Um dieses Problem lösen zu können, müsste ein Algorithmus, neben dem Position Tracking, den gesamten Zustandsraum prüfen. Bei einigen Anwendungen würde dies zu lange dauern. So wäre es auch denkbar, dass nicht der gesamte Zustandsraum für jede Messung durchsucht wird, sondern nur Teile davon. Entweder systematisch, so dass nach einer gewissen Zeit ebenfalls der gesamte Zustandsraum durchsucht ist, oder durch zufällige Ziehungen aus dem Gesamtvolumen des Zustandsraums, so dass eine Wahrscheinlichkeit besteht den wahren Zustand zu treffen. 
\end{description}

\subsection{Übersicht gängiger Verfahren}
\label{subsec:uebersichtVerfahren}
Die meisten Lösungsansätze verwenden im Grunde eine Variante des Bayes-Filters wie z.B. in \cite[Seite 26]{Thrun2006} beschrieben. Abhängig vom Einsatzumfeld und der verwendeten Sensoren gibt es aber noch andere Verfahren.

In \cite{seco2009survey} zum Beispiel werden, neben dem Bayes-Filter, drei weitere genannt: \textit{Geometry-Based Methods}, \textit{Minimization of the cost function} und \textit{Fingerprint Methods} die sich in Gebäuden unter Nutzung von Elektromagnetischen Signale verwenden lassen. Je nach Sensorausstattung werden verschiedene Karten der Umgebung verwendet. Auf die sich der Roboter durch Auswertung von Sensormessungen lokalisieren muss. Dabei gibt es Karten die vorher angefertigt wurden, und dem Roboter bereits zur Verfügung stehen. Und es gibt Karten die der Roboter selbstständig während der Lokalisation erstellen muss. Letzteres wird als \ac{SLAM} Problem bezeichnet zu dem es bereits viele Veröffentlichungen gibt (u.a.) \cite[Seite 309]{Thrun2006}, \cite{Thrun:2002:PFR:2073876.2073937}, \cite[Seite 229]{Hertzberg2012}.

Der in Kapitel \ref{chap:einleitung} erwähnte Partikelfilter ist eine Variante des Bayes-Filters. Er ist auch als \ac{MCL} bekannt. Alternativ dazu gibt es zum Beispiel den Kalman Filter, der mit Normalverteilungen die Wahrscheinlichkeiten abbildet. Er ist in seiner Anwendbarkeit auf lineare Probleme beschränkt oder ist auf Linearisierung angewiesen. Dafür ist er aber eines der ältesten Verfahren und damit am besten untersucht. In \cite{HaXInte2012} wird er bei einem Lokalisationsproblem verwendet. Außerdem gibt es noch so genannte Grid-Based-Filter oder Histogram Filter. Diese teilen den Zustandsraum in so genannte Grids auf in denen ein Wahrscheinlichkeitswert jeweils den Zustand der Region abbildet. Für bestimmte Probleme mit nur zwei Zuständen, kann ein Binary Bayes Filter zum Einsatz kommen. Da in dieser Arbeit ein Partikelfilter verwendet wird, soll seine Funktionsweise kurz erklärt werden.

\subsection{Der Partikelfilter}
\label{subsec:partikelfilter}
\subsubsection*{Zustandsraum}
Der Partikelfilter bildet die Wahrscheinlichkeitsverteilung des vermuteten Zustandes durch eine diskrete Menge von so genannten Partikeln ab. Ein Partikel ist dabei ein Punkt im Zustandsraum zu dem noch ein Gewichtungswert gehört. Angenommen, der Zustand wäre die Position in einem dreidimensionalen Koordinatensystem ist, dann wäre der Zustandsraum alle möglichen Punkte in diesem Koordinatensystem. Ein Partikel in diesem Raum hätte also vier Attribute: einen X-Wert, einen Y-Wert, einen Z-Wert und einen Gewichtungswert. Im Grundzustand, ist der Gewichtungswert bei allen Partikeln gleich und die räumliche Verteilung oder Häufung repräsentiert die Wahrscheinlichkeitsverteilung des vermuteten Zustandes (hier die Position im Koordinatensystem). Häuften sich die Partikel um eine Position, so wäre bei einer zufälligen Ziehung aus den Partikeln, die Wahrscheinlichkeit höher ein Partikel von dieser Position zu ziehen. Mittelt man nun über alle Partikel im Zustandsraum, so erhält man eine Position die dem vermuteten Zustand entspricht. Dabei ist die Varianz über alle Partikel ein Maß dafür, wie zuverlässig diese Position ist.

\subsubsection*{Dynamikmodell}
Partikelfilter nutzen für die Zustandsschätzung ein Dynamikmodell. In diesem Modell wird abgebildet, wie sich der Zustand über die Zeit verändert, z.B. durch Physikalische Gesetzmäßigkeiten oder durch eine Hilfsgröße die sich messen lässt (z.B. zurück gelegter Weg). Damit erlaubt das Dynamikmodell eine Prognose über den nächsten Zustand abzugeben. Um das Beispiel weiter zu führen stelle man sich vor, man will die Position eines Satelliten der um die Erde kreist bestimmten. Dabei soll lediglich die Position im Raum und nicht seine Orientierung betrachtet werden. Der Zustandsraum besteht damit schon einmal aus X, Y, und Z-Koordinaten. Für das Dynamikmodell könnten hier die Keplerschen Gesetzte zur Bahnberechnung verwendet werden. Allerdings ist es dafür nötig, die Geschwindigkeit des Objektes zu kennen. Dazu wird der Zustandsraum um die Geschwindigkeiten in X, Y und Z-Richtung erweitert. Nun ist es bei einem gegebenen Zustand möglich einen Folgezustand nach einer verstrichenen Zeit zu errechnen. Leider wird diese Prognose mit der Zeit immer ungenauer, denn in der Realität gibt es immer Störgrößen, die sich nicht vorhersagen lassen. Häufig jedoch lassen sich Aussagen über die Art und Stärke der Störung machen. Dieses Wissen kann in Form von einer Wahrscheinlichkeitsverteilung um die Prognose verwendet werden. Bei dem Satelliten wäre als Störung der Einfluss von Sonnenwind denkbar der ihn von der Sonne weg beschleunigt. Weiß man wie stark der Einfluss werden kann, könnte man ihn als Statistische Größe in die Prognose einfließen lassen. 

\subsubsection*{Messmodell}
Das Messmodell wird benötigt, um entscheiden zu können, wie plausibel eine Messung bei gegebenem Zustand (Im Beispiel die Position) ist. Ein Sensor, über den das System verfügt, liefert einen Messwert. Mit dem Messmodell kann jetzt zu einem beliebigen Zustand eine Aussage darüber gemacht werden, wie wahrscheinlich es wäre diesen Messwert zu messen. Im Beispiel des Satelliten könnte der Abstand zu einer Bodenstation gemessen werden. Im Messmodell würde dann aus einem gegebenen Zustand, also Position und Geschwindigkeit, zusammen mit weiteren Informationen wie Position der Bodenstation auf der Erde, Datum und Uhrzeit der Messung errechnet werden wie groß der Abstand sein müsste. Je stärker dieser erwartete Abstand von dem gemessenen abweicht, um so unwahrscheinlicher ist die Messung bei diesem Zustand (Position und Geschwindigkeit). Zusätzlich ist natürlich jeder Messwert mit einer Ungenauigkeit behaftet, die vom Messprinzip und Sensortyp abhängt. Aber auch diese lässt sich statistisch angeben und auf den Messwert aufschlagen bevor er ins Messmodell gegeben wird. So lassen sich Zustände im Zustandsraum hervorheben, für die eine gegebene Messung wahrscheinlich sind.

\subsubsection*{Angewendet auf den Filter}
Wenn der Zustandsraum alle möglichen Zustände eines Systems beschreibt, so sind die Partikel des Partikelfilters eine Untermenge davon, die in ihrer räumlichen Häufung den tatsächlichen Zustand des Systems beschreiben. Während des Betriebs gibt es zwei Ereignisse auf die der Filter reagiert:

Das \textbf{Dynamik-Update} berechnet auf Grundlage des Dynamikmodells eine neue Prognose. Konkret wird im Partikelfilter dafür zu jedem Partikel eine eigene Prognose gestellt. Dabei wird eventuelles Systemrauschen durch eine Ziehung pro Partikel aus dessen Wahrscheinlichkeitsverteilung (häufig Gaußverteilung) abgebildet. Die Prognosen aller Partikel bilden dann den neuen Systemzustand.

Der \textbf{Mess-Update} Aufruf verarbeitet eine Messung mit Hilfe des Messmodells. Konkret wird für jedes Partikel, und damit den Zustand den es repräsentiert, geprüft wie wahrscheinlich eine solche Messung wäre. Bei einer hohen Wahrscheinlichkeit, wird der Gewichtungswert im Partikel größer. Bei geringer Wahrscheinlichkeit für eine solche Messung sinkt der Gewichtungswert. Nun repräsentieren diese Gewichte der Partikel den neuen Systemzustand.

Ein \textbf{Resampling} überführt die Information in den Partikelgewichten wieder in die Partikelhäufung. Es wird normaler weise nach jedem Mess-Update vorgenommen. Dies geschieht durch Ziehen von Partikeln aus der alten Partikelmenge mit einer Wahrscheinlichkeit die proportional zum Gewicht eines Partikels ist. Somit werden Partikel die ein hohes Gewicht hatten häufiger gezogen als jene, die nur ein geringes Gewicht hatten. Damit "überleben" das Resampling die Partikel dessen Zustand von einer vorgenommenen Messung bestätigt wird. Nach der Neuziehung wird das Gesamtpartikelgewicht wieder auf 1 normalisiert und alle Partikel erhalten das selbe Gewicht. In \cite[Seite 108]{Thrun2006} wird ein Problem beim Resampling beschrieben, welches bei unabhängigen Ziehungen auftritt. Es wird \textsc{variance reduction} genannt und führt dazu, das Partikel mit geringem Gewicht zufällig gar nicht gezogen werden. Dies bedeutet einen Informationsverlust, der mit wiederholtem Resampling im Extremfall auf nur einen einzigen Zustand degeneriert. Um dem entgegen zu wirken, sollte das Resampling nur durchgeführt werden, wenn sich die Gewichte in den Partikeln verändert haben. Also nach einer Messung beispielsweise. Weiß man jedoch sicher, dass sich am Zustand nichts ändern kann (z.B. Roboter steht still) sollte man weder Messungen auswerten, noch ein Resampling durchführen. Zudem sollte systematisches Ziehen anstelle von unabhängigen Ziehungen eingesetzt werden. Hierbei wird ein Partikel zufällig ausgewählt, und die übrigen systematisch anhand ihrer Gewichtung ermittelt.

\section{Bildverarbeitung}
\label{sec:bildverarbeitung}
Da die von einer Kamera aufgenommenen Bilder in dieser Arbeit eine zentrale Rolle spielen, ist es wichtig zu verstehen, wie diese zustande kommen. Daher soll an dieser Stelle kurz darauf eingegangen werden, wie sich eine Kamera formal beschreiben lässt.

Die Lochkamera ist ein sehr einfaches Modell das häufig zur Veranschaulichung verwendet wird. Es soll hier nicht im Detail beschrieben werden, dafür wären \cite[Seite 203]{JaehDigi2005} oder \cite[Seite 47]{ToenGrun2005} zu empfehlen. Doch für das hier vorgestellte Verfahren ist es wichtig das Konzept dahinter zu verstehen:

Die Kamera projiziert im Wesentlichen Punkte aus dem Raum(3D) auf die Bildebene(2D). Um nun bei gegebenen Koordinaten eines 3D-Punktes in Weltkoordinaten den passenden Punkt auf der Bildebene berechnen zu können, ist die Kenntnis verschiedener Parameter erforderlich. Dabei trennt man in extrinsische und intrinsische Parameter. Unter den extrinsichen Kamera Parametern versteht man die Pose der Kamera in Weltkoordinaten, also wo sich sie befindet und wie sie ausgerichtet ist. Dies wird in einer Transformationsmatrix ausgedrückt, mit der sich Punkte zwischen dem Kamera- und Weltkoordinatensystem  transformieren lassen.

Die intrinsischen Parameter sind nötig, um 3D-Punkte (in Kamerakoordinaten) auf die Bildebene und in Pixelkoordinaten zu projizieren. Sie beinhalten neben der Brennweite, auch die Koordinaten wo die optische Achse auf den Bildsensor trifft. Um die auf den Bildsensor projizierten Punkte auch in Pixeln angeben zu können, gibt es einen Skalierungsfaktor.

Bei realen Kameras, muss in der Regel eine Kalibrierung durchgeführt werden, um diese Parameter zu bestimmen. Dabei können die intrinsischen Parameter gespeichert und wieder verwendet werden, wenn sich die Brennweite nicht ändert (kein optischer Zoom). Die extrinsischen Parameter müssen neu bestimmt werden, sobald sich die Kamera bewegt. Oder die Bewegung muss bekannt sein um sie in die Transformationsmatrix ein fließen zu lassen. 


